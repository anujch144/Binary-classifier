{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd \n\nimport os","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Importing all necessary libraries\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.models import Sequential\nfrom keras.layers import Conv2D, MaxPooling2D\nfrom keras.layers import Activation, Dropout, Flatten, Dense\nfrom keras import backend as K\n\nimg_width, img_height = 224, 224\n","metadata":{"execution":{"iopub.status.busy":"2022-04-09T06:53:31.309099Z","iopub.execute_input":"2022-04-09T06:53:31.309417Z","iopub.status.idle":"2022-04-09T06:53:31.317593Z","shell.execute_reply.started":"2022-04-09T06:53:31.309386Z","shell.execute_reply":"2022-04-09T06:53:31.316447Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"train_data_dir = '../input/image1/data1a/training'\nvalidation_data_dir = '../input/image1/data1a/validation'\nnb_train_samples =1000\nnb_validation_samples = 400\nepochs = 20\nbatch_size = 8\n","metadata":{"execution":{"iopub.status.busy":"2022-04-09T06:53:31.655350Z","iopub.execute_input":"2022-04-09T06:53:31.656594Z","iopub.status.idle":"2022-04-09T06:53:31.661234Z","shell.execute_reply.started":"2022-04-09T06:53:31.656448Z","shell.execute_reply":"2022-04-09T06:53:31.660397Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"if K.image_data_format() == 'channels_first':\n    input_shape = (3, img_width, img_height)\nelse:\n    input_shape = (img_width, img_height, 3)","metadata":{"execution":{"iopub.status.busy":"2022-04-09T06:53:32.066326Z","iopub.execute_input":"2022-04-09T06:53:32.066605Z","iopub.status.idle":"2022-04-09T06:53:32.072342Z","shell.execute_reply.started":"2022-04-09T06:53:32.066575Z","shell.execute_reply":"2022-04-09T06:53:32.071559Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"model = Sequential()\nmodel.add(Conv2D(32, (3, 3), input_shape=input_shape))\nmodel.add(Activation('relu'))\nmodel.add(MaxPooling2D(pool_size=(3, 3)))\n\nmodel.add(Conv2D(32, (3, 3)))\nmodel.add(Activation('relu'))\nmodel.add(MaxPooling2D(pool_size=(3, 3)))\n\nmodel.add(Conv2D(64, (3, 3)))\nmodel.add(Activation('relu'))\nmodel.add(MaxPooling2D(pool_size=(3, 3)))\n\nmodel.add(Flatten())\nmodel.add(Dense(64))\nmodel.add(Activation('relu'))\nmodel.add(Dropout(0.3))\nmodel.add(Dense(1))\nmodel.add(Activation('sigmoid'))\n","metadata":{"execution":{"iopub.status.busy":"2022-04-09T06:53:32.543057Z","iopub.execute_input":"2022-04-09T06:53:32.543453Z","iopub.status.idle":"2022-04-09T06:53:32.634252Z","shell.execute_reply.started":"2022-04-09T06:53:32.543425Z","shell.execute_reply":"2022-04-09T06:53:32.633219Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"model.compile(loss='binary_crossentropy',\n\t\t\toptimizer='rmsprop',\n\t\t\tmetrics=['accuracy'])\n","metadata":{"execution":{"iopub.status.busy":"2022-04-09T06:53:32.901302Z","iopub.execute_input":"2022-04-09T06:53:32.901705Z","iopub.status.idle":"2022-04-09T06:53:32.911789Z","shell.execute_reply.started":"2022-04-09T06:53:32.901676Z","shell.execute_reply":"2022-04-09T06:53:32.910624Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"train_datagen = ImageDataGenerator(\n\trescale=1. / 255,\n\tshear_range=0.2,\n\tzoom_range=0.2,\n\thorizontal_flip=True)\n\ntest_datagen = ImageDataGenerator(rescale=1. / 255)\n\ntrain_generator = train_datagen.flow_from_directory(\n\ttrain_data_dir,\n\ttarget_size=(img_width, img_height),\n\tbatch_size=batch_size,\n\tclass_mode='binary')\n\nvalidation_generator = test_datagen.flow_from_directory(\n\tvalidation_data_dir,\n\ttarget_size=(img_width, img_height),\n\tbatch_size=batch_size,\n\tclass_mode='binary')\n\nmodel.fit_generator(\n\ttrain_generator,\n\tsteps_per_epoch=nb_train_samples // batch_size,\n\tepochs=epochs,\n\tvalidation_data=validation_generator,\n\tvalidation_steps=nb_validation_samples // batch_size)\n","metadata":{"execution":{"iopub.status.busy":"2022-04-09T06:53:33.358595Z","iopub.execute_input":"2022-04-09T06:53:33.358922Z","iopub.status.idle":"2022-04-09T07:05:15.483244Z","shell.execute_reply.started":"2022-04-09T06:53:33.358896Z","shell.execute_reply":"2022-04-09T07:05:15.482063Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"import numpy as np\nfrom keras.models import load_model\nfrom keras.preprocessing.image import load_img\nfrom keras.preprocessing.image import img_to_array\nimage = load_img('../input/image1/data1a/validation/00-damage/0004.JPEG', target_size=(224, 224))\nimg = np.array(image)\nimg = img / 255.0\nimg = img.reshape(1,224,224,3)\nlabel = model.predict(img)\nprint( label)","metadata":{"execution":{"iopub.status.busy":"2022-04-09T07:10:33.689491Z","iopub.execute_input":"2022-04-09T07:10:33.690126Z","iopub.status.idle":"2022-04-09T07:10:33.782621Z","shell.execute_reply.started":"2022-04-09T07:10:33.690093Z","shell.execute_reply":"2022-04-09T07:10:33.781223Z"},"trusted":true},"execution_count":27,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}